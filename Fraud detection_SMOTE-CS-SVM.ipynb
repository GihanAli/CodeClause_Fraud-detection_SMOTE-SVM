{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "> This project is concerned with the credit card fraud detection in imbalanced data. Particularly, the project aims at  proposing a novel model referred to as SMOTE-CS-SVM integrating the application of The Synthetic Minority Oversampling Technique (SMOTE) with Cost sensitive support vector machine (CS-SVM). Importantly, the results reveal the superiority of the proposed model over other state-of-the-art imbalanced classifiers in terms of accuracy and ROC-AUC scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported Libraries\n",
    "import numpy as np\n",
    "from numpy import linalg\n",
    "import cvxopt\n",
    "import cvxopt.solvers\n",
    "import pandas as pd\n",
    "#from sklearn import cross_validation\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from cvxopt import matrix as cvxopt_matrix\n",
    "from cvxopt import solvers as cvxopt_solvers\n",
    "from sklearn import svm\n",
    "import math \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.176563</td>\n",
       "      <td>0.323798</td>\n",
       "      <td>0.536927</td>\n",
       "      <td>1.047002</td>\n",
       "      <td>-0.368652</td>\n",
       "      <td>-0.728586</td>\n",
       "      <td>0.084678</td>\n",
       "      <td>-0.069246</td>\n",
       "      <td>-0.266389</td>\n",
       "      <td>0.155315</td>\n",
       "      <td>1.535776</td>\n",
       "      <td>1.019947</td>\n",
       "      <td>-0.096511</td>\n",
       "      <td>0.573023</td>\n",
       "      <td>0.215214</td>\n",
       "      <td>0.265249</td>\n",
       "      <td>-0.612064</td>\n",
       "      <td>0.093821</td>\n",
       "      <td>-0.064890</td>\n",
       "      <td>-0.137258</td>\n",
       "      <td>-0.109627</td>\n",
       "      <td>-0.341365</td>\n",
       "      <td>0.057845</td>\n",
       "      <td>0.499180</td>\n",
       "      <td>0.415211</td>\n",
       "      <td>-0.581949</td>\n",
       "      <td>0.015472</td>\n",
       "      <td>0.018065</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.681109</td>\n",
       "      <td>-3.934776</td>\n",
       "      <td>-3.801827</td>\n",
       "      <td>-1.147468</td>\n",
       "      <td>-0.735540</td>\n",
       "      <td>-0.501097</td>\n",
       "      <td>1.038865</td>\n",
       "      <td>-0.626979</td>\n",
       "      <td>-2.274423</td>\n",
       "      <td>1.527782</td>\n",
       "      <td>-0.007688</td>\n",
       "      <td>-1.087403</td>\n",
       "      <td>-0.720270</td>\n",
       "      <td>0.855185</td>\n",
       "      <td>-1.070011</td>\n",
       "      <td>-0.869661</td>\n",
       "      <td>0.395302</td>\n",
       "      <td>0.635695</td>\n",
       "      <td>0.249401</td>\n",
       "      <td>1.341809</td>\n",
       "      <td>0.652202</td>\n",
       "      <td>0.272684</td>\n",
       "      <td>-0.982151</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>0.360251</td>\n",
       "      <td>0.195321</td>\n",
       "      <td>-0.256273</td>\n",
       "      <td>0.056501</td>\n",
       "      <td>912.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.140729</td>\n",
       "      <td>0.453484</td>\n",
       "      <td>0.247010</td>\n",
       "      <td>2.383132</td>\n",
       "      <td>0.343287</td>\n",
       "      <td>0.432804</td>\n",
       "      <td>0.093380</td>\n",
       "      <td>0.173310</td>\n",
       "      <td>-0.808999</td>\n",
       "      <td>0.775436</td>\n",
       "      <td>0.726218</td>\n",
       "      <td>0.347648</td>\n",
       "      <td>-0.806752</td>\n",
       "      <td>0.531268</td>\n",
       "      <td>-0.806538</td>\n",
       "      <td>0.154996</td>\n",
       "      <td>-0.319935</td>\n",
       "      <td>-0.335550</td>\n",
       "      <td>-0.648994</td>\n",
       "      <td>-0.232185</td>\n",
       "      <td>-0.003802</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>-0.121177</td>\n",
       "      <td>-0.304215</td>\n",
       "      <td>0.645893</td>\n",
       "      <td>0.122600</td>\n",
       "      <td>-0.012115</td>\n",
       "      <td>-0.005945</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.107073</td>\n",
       "      <td>-3.298902</td>\n",
       "      <td>-0.184092</td>\n",
       "      <td>-1.795744</td>\n",
       "      <td>2.137564</td>\n",
       "      <td>-1.684992</td>\n",
       "      <td>-2.015606</td>\n",
       "      <td>-0.007181</td>\n",
       "      <td>-0.165760</td>\n",
       "      <td>0.869659</td>\n",
       "      <td>-1.027847</td>\n",
       "      <td>-3.220699</td>\n",
       "      <td>3.007008</td>\n",
       "      <td>0.794679</td>\n",
       "      <td>-1.504351</td>\n",
       "      <td>-0.380985</td>\n",
       "      <td>0.667344</td>\n",
       "      <td>0.676138</td>\n",
       "      <td>-0.419469</td>\n",
       "      <td>0.348269</td>\n",
       "      <td>0.130648</td>\n",
       "      <td>0.329445</td>\n",
       "      <td>0.927656</td>\n",
       "      <td>-0.049560</td>\n",
       "      <td>-1.892866</td>\n",
       "      <td>-0.575431</td>\n",
       "      <td>0.266573</td>\n",
       "      <td>0.414184</td>\n",
       "      <td>62.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.314818</td>\n",
       "      <td>0.866839</td>\n",
       "      <td>-0.124577</td>\n",
       "      <td>-0.627638</td>\n",
       "      <td>2.651762</td>\n",
       "      <td>3.428128</td>\n",
       "      <td>0.194637</td>\n",
       "      <td>0.670674</td>\n",
       "      <td>-0.442658</td>\n",
       "      <td>0.133499</td>\n",
       "      <td>0.148566</td>\n",
       "      <td>-0.474103</td>\n",
       "      <td>-0.011319</td>\n",
       "      <td>-0.410223</td>\n",
       "      <td>1.648979</td>\n",
       "      <td>0.218394</td>\n",
       "      <td>-0.239475</td>\n",
       "      <td>0.422933</td>\n",
       "      <td>1.274986</td>\n",
       "      <td>0.402329</td>\n",
       "      <td>-0.312774</td>\n",
       "      <td>-0.799494</td>\n",
       "      <td>-0.064488</td>\n",
       "      <td>0.953062</td>\n",
       "      <td>-0.429550</td>\n",
       "      <td>0.158225</td>\n",
       "      <td>0.076943</td>\n",
       "      <td>-0.015051</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0  1.176563  0.323798  0.536927  1.047002 -0.368652 -0.728586  0.084678   \n",
       "1  0.681109 -3.934776 -3.801827 -1.147468 -0.735540 -0.501097  1.038865   \n",
       "2  1.140729  0.453484  0.247010  2.383132  0.343287  0.432804  0.093380   \n",
       "3 -1.107073 -3.298902 -0.184092 -1.795744  2.137564 -1.684992 -2.015606   \n",
       "4 -0.314818  0.866839 -0.124577 -0.627638  2.651762  3.428128  0.194637   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0 -0.069246 -0.266389  0.155315  1.535776  1.019947 -0.096511  0.573023   \n",
       "1 -0.626979 -2.274423  1.527782 -0.007688 -1.087403 -0.720270  0.855185   \n",
       "2  0.173310 -0.808999  0.775436  0.726218  0.347648 -0.806752  0.531268   \n",
       "3 -0.007181 -0.165760  0.869659 -1.027847 -3.220699  3.007008  0.794679   \n",
       "4  0.670674 -0.442658  0.133499  0.148566 -0.474103 -0.011319 -0.410223   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  0.215214  0.265249 -0.612064  0.093821 -0.064890 -0.137258 -0.109627   \n",
       "1 -1.070011 -0.869661  0.395302  0.635695  0.249401  1.341809  0.652202   \n",
       "2 -0.806538  0.154996 -0.319935 -0.335550 -0.648994 -0.232185 -0.003802   \n",
       "3 -1.504351 -0.380985  0.667344  0.676138 -0.419469  0.348269  0.130648   \n",
       "4  1.648979  0.218394 -0.239475  0.422933  1.274986  0.402329 -0.312774   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0 -0.341365  0.057845  0.499180  0.415211 -0.581949  0.015472  0.018065   \n",
       "1  0.272684 -0.982151  0.165900  0.360251  0.195321 -0.256273  0.056501   \n",
       "2  0.058556 -0.121177 -0.304215  0.645893  0.122600 -0.012115 -0.005945   \n",
       "3  0.329445  0.927656 -0.049560 -1.892866 -0.575431  0.266573  0.414184   \n",
       "4 -0.799494 -0.064488  0.953062 -0.429550  0.158225  0.076943 -0.015051   \n",
       "\n",
       "   Amount  Class  \n",
       "0    4.67      0  \n",
       "1  912.00      0  \n",
       "2    1.00      0  \n",
       "3   62.10      0  \n",
       "4    2.67      0  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data and print out a few lines. \n",
    "df = pd.read_csv(r\"C:\\Users\\Kimo Store\\fraud_data.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21693, 30)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the data shape (we have 21693 observations with 30 features)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describe the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.032403</td>\n",
       "      <td>0.047565</td>\n",
       "      <td>-0.091623</td>\n",
       "      <td>0.057805</td>\n",
       "      <td>-0.033983</td>\n",
       "      <td>-0.023207</td>\n",
       "      <td>-0.074203</td>\n",
       "      <td>0.002096</td>\n",
       "      <td>-0.044311</td>\n",
       "      <td>-0.091073</td>\n",
       "      <td>0.067173</td>\n",
       "      <td>-0.094268</td>\n",
       "      <td>-0.000667</td>\n",
       "      <td>-0.091499</td>\n",
       "      <td>-0.003917</td>\n",
       "      <td>-0.055079</td>\n",
       "      <td>-0.098357</td>\n",
       "      <td>-0.033488</td>\n",
       "      <td>0.021861</td>\n",
       "      <td>-0.001762</td>\n",
       "      <td>0.012471</td>\n",
       "      <td>0.003743</td>\n",
       "      <td>-0.001662</td>\n",
       "      <td>-0.002446</td>\n",
       "      <td>-0.000406</td>\n",
       "      <td>0.002367</td>\n",
       "      <td>0.001514</td>\n",
       "      <td>0.003203</td>\n",
       "      <td>86.776247</td>\n",
       "      <td>0.016411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.106997</td>\n",
       "      <td>1.690911</td>\n",
       "      <td>1.870289</td>\n",
       "      <td>1.540329</td>\n",
       "      <td>1.530508</td>\n",
       "      <td>1.340599</td>\n",
       "      <td>1.596775</td>\n",
       "      <td>1.412650</td>\n",
       "      <td>1.158554</td>\n",
       "      <td>1.354886</td>\n",
       "      <td>1.154227</td>\n",
       "      <td>1.364933</td>\n",
       "      <td>0.989655</td>\n",
       "      <td>1.356199</td>\n",
       "      <td>0.916582</td>\n",
       "      <td>1.096472</td>\n",
       "      <td>1.424975</td>\n",
       "      <td>0.936769</td>\n",
       "      <td>0.843902</td>\n",
       "      <td>0.727979</td>\n",
       "      <td>0.850009</td>\n",
       "      <td>0.741348</td>\n",
       "      <td>0.629987</td>\n",
       "      <td>0.600144</td>\n",
       "      <td>0.520949</td>\n",
       "      <td>0.478279</td>\n",
       "      <td>0.424688</td>\n",
       "      <td>0.302048</td>\n",
       "      <td>235.644479</td>\n",
       "      <td>0.127052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-41.928738</td>\n",
       "      <td>-40.803981</td>\n",
       "      <td>-31.103685</td>\n",
       "      <td>-4.848504</td>\n",
       "      <td>-32.092129</td>\n",
       "      <td>-20.367836</td>\n",
       "      <td>-41.506796</td>\n",
       "      <td>-38.987263</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>-24.403185</td>\n",
       "      <td>-3.995739</td>\n",
       "      <td>-18.553697</td>\n",
       "      <td>-3.844974</td>\n",
       "      <td>-19.214325</td>\n",
       "      <td>-4.498945</td>\n",
       "      <td>-14.129855</td>\n",
       "      <td>-24.019099</td>\n",
       "      <td>-9.498746</td>\n",
       "      <td>-4.395283</td>\n",
       "      <td>-21.024817</td>\n",
       "      <td>-21.453736</td>\n",
       "      <td>-8.887017</td>\n",
       "      <td>-21.303666</td>\n",
       "      <td>-2.766638</td>\n",
       "      <td>-4.541819</td>\n",
       "      <td>-1.855355</td>\n",
       "      <td>-7.764147</td>\n",
       "      <td>-6.520075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.929371</td>\n",
       "      <td>-0.592921</td>\n",
       "      <td>-0.962975</td>\n",
       "      <td>-0.850069</td>\n",
       "      <td>-0.698296</td>\n",
       "      <td>-0.779041</td>\n",
       "      <td>-0.565297</td>\n",
       "      <td>-0.205943</td>\n",
       "      <td>-0.669752</td>\n",
       "      <td>-0.554596</td>\n",
       "      <td>-0.739193</td>\n",
       "      <td>-0.438730</td>\n",
       "      <td>-0.634030</td>\n",
       "      <td>-0.438416</td>\n",
       "      <td>-0.582193</td>\n",
       "      <td>-0.492689</td>\n",
       "      <td>-0.498984</td>\n",
       "      <td>-0.513216</td>\n",
       "      <td>-0.444441</td>\n",
       "      <td>-0.209710</td>\n",
       "      <td>-0.225142</td>\n",
       "      <td>-0.538258</td>\n",
       "      <td>-0.162395</td>\n",
       "      <td>-0.356356</td>\n",
       "      <td>-0.317296</td>\n",
       "      <td>-0.326141</td>\n",
       "      <td>-0.069938</td>\n",
       "      <td>-0.053334</td>\n",
       "      <td>5.370000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.007545</td>\n",
       "      <td>0.075215</td>\n",
       "      <td>0.176534</td>\n",
       "      <td>-0.012868</td>\n",
       "      <td>-0.063948</td>\n",
       "      <td>-0.281565</td>\n",
       "      <td>0.030859</td>\n",
       "      <td>0.023159</td>\n",
       "      <td>-0.073996</td>\n",
       "      <td>-0.099291</td>\n",
       "      <td>0.005596</td>\n",
       "      <td>0.126666</td>\n",
       "      <td>-0.018642</td>\n",
       "      <td>0.044870</td>\n",
       "      <td>0.048753</td>\n",
       "      <td>0.059504</td>\n",
       "      <td>-0.075797</td>\n",
       "      <td>-0.019269</td>\n",
       "      <td>0.021719</td>\n",
       "      <td>-0.057330</td>\n",
       "      <td>-0.024133</td>\n",
       "      <td>0.007273</td>\n",
       "      <td>-0.012327</td>\n",
       "      <td>0.036878</td>\n",
       "      <td>0.011561</td>\n",
       "      <td>-0.044870</td>\n",
       "      <td>0.002475</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>21.950000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.315678</td>\n",
       "      <td>0.819749</td>\n",
       "      <td>1.020809</td>\n",
       "      <td>0.772388</td>\n",
       "      <td>0.615287</td>\n",
       "      <td>0.383633</td>\n",
       "      <td>0.563751</td>\n",
       "      <td>0.328411</td>\n",
       "      <td>0.590212</td>\n",
       "      <td>0.445474</td>\n",
       "      <td>0.786044</td>\n",
       "      <td>0.613676</td>\n",
       "      <td>0.652241</td>\n",
       "      <td>0.490003</td>\n",
       "      <td>0.642463</td>\n",
       "      <td>0.525327</td>\n",
       "      <td>0.389992</td>\n",
       "      <td>0.494700</td>\n",
       "      <td>0.484930</td>\n",
       "      <td>0.139059</td>\n",
       "      <td>0.192954</td>\n",
       "      <td>0.530333</td>\n",
       "      <td>0.146616</td>\n",
       "      <td>0.431931</td>\n",
       "      <td>0.354043</td>\n",
       "      <td>0.238629</td>\n",
       "      <td>0.095859</td>\n",
       "      <td>0.081749</td>\n",
       "      <td>76.480000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.451888</td>\n",
       "      <td>21.467203</td>\n",
       "      <td>4.069865</td>\n",
       "      <td>12.114672</td>\n",
       "      <td>29.162172</td>\n",
       "      <td>21.393069</td>\n",
       "      <td>34.303177</td>\n",
       "      <td>20.007208</td>\n",
       "      <td>9.125535</td>\n",
       "      <td>12.701539</td>\n",
       "      <td>12.018913</td>\n",
       "      <td>3.966626</td>\n",
       "      <td>4.099352</td>\n",
       "      <td>6.441021</td>\n",
       "      <td>5.720479</td>\n",
       "      <td>6.442798</td>\n",
       "      <td>6.609366</td>\n",
       "      <td>3.790316</td>\n",
       "      <td>4.851255</td>\n",
       "      <td>13.119819</td>\n",
       "      <td>27.202839</td>\n",
       "      <td>8.361985</td>\n",
       "      <td>15.626067</td>\n",
       "      <td>4.014444</td>\n",
       "      <td>5.541598</td>\n",
       "      <td>3.463246</td>\n",
       "      <td>9.879903</td>\n",
       "      <td>9.876371</td>\n",
       "      <td>7712.430000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 V1            V2            V3            V4            V5  \\\n",
       "count  21693.000000  21693.000000  21693.000000  21693.000000  21693.000000   \n",
       "mean      -0.032403      0.047565     -0.091623      0.057805     -0.033983   \n",
       "std        2.106997      1.690911      1.870289      1.540329      1.530508   \n",
       "min      -41.928738    -40.803981    -31.103685     -4.848504    -32.092129   \n",
       "25%       -0.929371     -0.592921     -0.962975     -0.850069     -0.698296   \n",
       "50%        0.007545      0.075215      0.176534     -0.012868     -0.063948   \n",
       "75%        1.315678      0.819749      1.020809      0.772388      0.615287   \n",
       "max        2.451888     21.467203      4.069865     12.114672     29.162172   \n",
       "\n",
       "                 V6            V7            V8            V9           V10  \\\n",
       "count  21693.000000  21693.000000  21693.000000  21693.000000  21693.000000   \n",
       "mean      -0.023207     -0.074203      0.002096     -0.044311     -0.091073   \n",
       "std        1.340599      1.596775      1.412650      1.158554      1.354886   \n",
       "min      -20.367836    -41.506796    -38.987263    -13.434066    -24.403185   \n",
       "25%       -0.779041     -0.565297     -0.205943     -0.669752     -0.554596   \n",
       "50%       -0.281565      0.030859      0.023159     -0.073996     -0.099291   \n",
       "75%        0.383633      0.563751      0.328411      0.590212      0.445474   \n",
       "max       21.393069     34.303177     20.007208      9.125535     12.701539   \n",
       "\n",
       "                V11           V12           V13           V14           V15  \\\n",
       "count  21693.000000  21693.000000  21693.000000  21693.000000  21693.000000   \n",
       "mean       0.067173     -0.094268     -0.000667     -0.091499     -0.003917   \n",
       "std        1.154227      1.364933      0.989655      1.356199      0.916582   \n",
       "min       -3.995739    -18.553697     -3.844974    -19.214325     -4.498945   \n",
       "25%       -0.739193     -0.438730     -0.634030     -0.438416     -0.582193   \n",
       "50%        0.005596      0.126666     -0.018642      0.044870      0.048753   \n",
       "75%        0.786044      0.613676      0.652241      0.490003      0.642463   \n",
       "max       12.018913      3.966626      4.099352      6.441021      5.720479   \n",
       "\n",
       "                V16           V17           V18           V19           V20  \\\n",
       "count  21693.000000  21693.000000  21693.000000  21693.000000  21693.000000   \n",
       "mean      -0.055079     -0.098357     -0.033488      0.021861     -0.001762   \n",
       "std        1.096472      1.424975      0.936769      0.843902      0.727979   \n",
       "min      -14.129855    -24.019099     -9.498746     -4.395283    -21.024817   \n",
       "25%       -0.492689     -0.498984     -0.513216     -0.444441     -0.209710   \n",
       "50%        0.059504     -0.075797     -0.019269      0.021719     -0.057330   \n",
       "75%        0.525327      0.389992      0.494700      0.484930      0.139059   \n",
       "max        6.442798      6.609366      3.790316      4.851255     13.119819   \n",
       "\n",
       "                V21           V22           V23           V24           V25  \\\n",
       "count  21693.000000  21693.000000  21693.000000  21693.000000  21693.000000   \n",
       "mean       0.012471      0.003743     -0.001662     -0.002446     -0.000406   \n",
       "std        0.850009      0.741348      0.629987      0.600144      0.520949   \n",
       "min      -21.453736     -8.887017    -21.303666     -2.766638     -4.541819   \n",
       "25%       -0.225142     -0.538258     -0.162395     -0.356356     -0.317296   \n",
       "50%       -0.024133      0.007273     -0.012327      0.036878      0.011561   \n",
       "75%        0.192954      0.530333      0.146616      0.431931      0.354043   \n",
       "max       27.202839      8.361985     15.626067      4.014444      5.541598   \n",
       "\n",
       "                V26           V27           V28        Amount         Class  \n",
       "count  21693.000000  21693.000000  21693.000000  21693.000000  21693.000000  \n",
       "mean       0.002367      0.001514      0.003203     86.776247      0.016411  \n",
       "std        0.478279      0.424688      0.302048    235.644479      0.127052  \n",
       "min       -1.855355     -7.764147     -6.520075      0.000000      0.000000  \n",
       "25%       -0.326141     -0.069938     -0.053334      5.370000      0.000000  \n",
       "50%       -0.044870      0.002475      0.011765     21.950000      0.000000  \n",
       "75%        0.238629      0.095859      0.081749     76.480000      0.000000  \n",
       "max        3.463246      9.879903      9.876371   7712.430000      1.000000  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21693 entries, 0 to 21692\n",
      "Data columns (total 30 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   V1      21693 non-null  float64\n",
      " 1   V2      21693 non-null  float64\n",
      " 2   V3      21693 non-null  float64\n",
      " 3   V4      21693 non-null  float64\n",
      " 4   V5      21693 non-null  float64\n",
      " 5   V6      21693 non-null  float64\n",
      " 6   V7      21693 non-null  float64\n",
      " 7   V8      21693 non-null  float64\n",
      " 8   V9      21693 non-null  float64\n",
      " 9   V10     21693 non-null  float64\n",
      " 10  V11     21693 non-null  float64\n",
      " 11  V12     21693 non-null  float64\n",
      " 12  V13     21693 non-null  float64\n",
      " 13  V14     21693 non-null  float64\n",
      " 14  V15     21693 non-null  float64\n",
      " 15  V16     21693 non-null  float64\n",
      " 16  V17     21693 non-null  float64\n",
      " 17  V18     21693 non-null  float64\n",
      " 18  V19     21693 non-null  float64\n",
      " 19  V20     21693 non-null  float64\n",
      " 20  V21     21693 non-null  float64\n",
      " 21  V22     21693 non-null  float64\n",
      " 22  V23     21693 non-null  float64\n",
      " 23  V24     21693 non-null  float64\n",
      " 24  V25     21693 non-null  float64\n",
      " 25  V26     21693 non-null  float64\n",
      " 26  V27     21693 non-null  float64\n",
      " 27  V28     21693 non-null  float64\n",
      " 28  Amount  21693 non-null  float64\n",
      " 29  Class   21693 non-null  int64  \n",
      "dtypes: float64(29), int64(1)\n",
      "memory usage: 5.0 MB\n"
     ]
    }
   ],
   "source": [
    "# inspect data types and look for missing values (no missing values)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016410823768035772"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The percentage of the observations in the dataset are instances of fraud (the data is highly imbalanced)\n",
    "fraudInstances = float(sum(df['Class']==1))\n",
    "fraudInstances/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21693, 30), (21693, 29), (21693,))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the features into dependent and explanatory features\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Classifier with RBF kernel before applying SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting original data into train and test\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y,test_size=0.2,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall RBF KERNEL SVM accuracy:  0.9923945609587462\n",
      "Overall RBF KERNEL SVM ROC_AUC:  0.874954241565998\n",
      "[[4251   15]\n",
      " [  18   55]]\n"
     ]
    }
   ],
   "source": [
    "clf_svm1 = svm.SVC(kernel='rbf', gamma=0.0007, C=10000)\n",
    "clf_svm1.fit(X_train1, y_train1)\n",
    "y_pred_svm1 = clf_svm1.predict(X_test1) \n",
    "acc_svm1 = accuracy_score(y_test1, y_pred_svm1)\n",
    "auc_svm1 = roc_auc_score(y_test1, y_pred_svm1, average=None)\n",
    "print (\"Overall RBF KERNEL SVM accuracy: \",acc_svm1)\n",
    "print (\"Overall RBF KERNEL SVM ROC_AUC: \", auc_svm1)\n",
    "print(confusion_matrix(y_test1, y_pred_svm1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS-SVM Classifier with RBF kernel before applying SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall RBF KERNEL CS-SVM accuracy:  0.9912422217100715\n",
      "Overall RBF KERNEL CS-SVM ROC_AUC:  0.8743682124989564\n",
      "[[4246   20]\n",
      " [  18   55]]\n"
     ]
    }
   ],
   "source": [
    "cs_svm1 = svm.SVC(kernel='rbf', class_weight={0: 1, 1: 4}, gamma=0.0007, C=10000) \n",
    "\n",
    "cs_svm1.fit(X_train1, y_train1)\n",
    "y_pred_cs_svm1 = cs_svm1.predict(X_test1) \n",
    "acc_cs_svm1 = accuracy_score(y_test1, y_pred_cs_svm1)\n",
    "auc_cs_svm1 = roc_auc_score(y_test1, y_pred_cs_svm1, average=None)\n",
    "print (\"Overall RBF KERNEL CS-SVM accuracy: \", acc_cs_svm1)\n",
    "print (\"Overall RBF KERNEL CS-SVM ROC_AUC: \", auc_cs_svm1)\n",
    "print(confusion_matrix(y_test1, y_pred_cs_svm1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Easy Ensemble Classifier before applying SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Easy Ensemble Classifier accuracy:  0.9596681262963817\n",
      "Overall Easy Ensemble Classifier ROC_AUC:  0.96602476414337\n",
      "[[4093  173]\n",
      " [   2   71]]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.ensemble import EasyEnsembleClassifier \n",
    "\n",
    "eec1 = EasyEnsembleClassifier(random_state=42)\n",
    "eec1.fit(X_train1, y_train1) \n",
    "EasyEnsembleClassifier(...)\n",
    "y_pred_eec1 = eec1.predict(X_test1)\n",
    "acc_eec1 = accuracy_score(y_test1, y_pred_eec1)\n",
    "\n",
    "auc_eec1 = roc_auc_score(y_test1, y_pred_eec1, average=None)\n",
    "print (\"Overall Easy Ensemble Classifier accuracy: \", acc_eec1)\n",
    "print (\"Overall Easy Ensemble Classifier ROC_AUC: \", auc_eec1)\n",
    "print(confusion_matrix(y_test1, y_pred_eec1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE Technique (Over-Sampling):\n",
    "The Synthetic Minority Oversampling Technique where new examples can be synthesized from the existing examples. This is a type of data augmentation for the minority class to deal with the problem of imbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({0: 21337, 1: 3560})\n"
     ]
    }
   ],
   "source": [
    "## applying oversampling technique to make the ratio of minority class to majority class 1 to 6\n",
    "sm = SMOTE(sampling_strategy ={1: 3560, 0: 21337}, random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X, y)\n",
    "print('Resampled dataset shape %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4980, 29)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## splitting synthetic data into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res,test_size=0.2,random_state=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing CS-SVM with state-of-the-art calssifiers in dealing with Imbalanced data after  applying SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall LR accuracy:  0.9785140562248996\n",
      "Overall LR ROC_AUC:  0.9392424364419573\n",
      "[[4209   19]\n",
      " [  88  664]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "\n",
    "estimator = linear_model.LogisticRegression(solver=\"liblinear\", multi_class=\"ovr\")\n",
    "estimator.fit(X_train, y_train)\n",
    "y_pred_lr = estimator.predict(X_test) \n",
    "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
    "\n",
    "auc_cs_lr = roc_auc_score(y_test, y_pred_lr, average=None)\n",
    "print (\"Overall LR accuracy: \",acc_lr)\n",
    "\n",
    "print (\"Overall LR ROC_AUC: \", auc_cs_lr)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Classifier with RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall RBF KERNEL SVM accuracy:  0.9939759036144579\n",
      "Overall RBF KERNEL SVM ROC_AUC:  0.9915325137381993\n",
      "[[4207   21]\n",
      " [   9  743]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf_svm = svm.SVC(kernel='rbf', gamma=0.0007, C=10000)\n",
    "clf_svm.fit(X_train, y_train)\n",
    "y_pred_svm = clf_svm.predict(X_test) \n",
    "acc_svm = accuracy_score(y_test, y_pred_svm)\n",
    "auc_svm = roc_auc_score(y_test, y_pred_svm, average=None)\n",
    "print (\"Overall RBF KERNEL SVM accuracy: \",acc_svm)\n",
    "print (\"Overall RBF KERNEL SVM ROC_AUC: \", auc_svm)\n",
    "print(confusion_matrix(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost-sensitive SVM Classifier with RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall RBF KERNEL CS-SVM accuracy:  0.9943775100401606\n",
      "Overall RBF KERNEL CS-SVM ROC_AUC:  0.9923156665794401\n",
      "[[4208   20]\n",
      " [   8  744]]\n"
     ]
    }
   ],
   "source": [
    "cs_svm = svm.SVC(kernel='rbf', class_weight={0: 1, 1: 4}, gamma=0.0007, C=10000) \n",
    "\n",
    "cs_svm.fit(X_train, y_train)#0:1,1:2\n",
    "y_pred_cs_svm = cs_svm.predict(X_test) \n",
    "acc_cs_svm = accuracy_score(y_test, y_pred_cs_svm)\n",
    "auc_cs_svm = roc_auc_score(y_test, y_pred_cs_svm, average=None)\n",
    "print (\"Overall RBF KERNEL CS-SVM accuracy: \", acc_cs_svm)\n",
    "print (\"Overall RBF KERNEL CS-SVM ROC_AUC: \", auc_cs_svm)\n",
    "print(confusion_matrix(y_test, y_pred_cs_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Easy Ensemble Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Easy Ensemble Classifier accuracy:  0.9825301204819277\n",
      "Overall Easy Ensemble Classifier ROC_AUC:  0.9760455876728598\n",
      "[[4166   62]\n",
      " [  25  727]]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.ensemble import EasyEnsembleClassifier \n",
    "\n",
    "eec = EasyEnsembleClassifier(random_state=42)\n",
    "eec.fit(X_train, y_train) \n",
    "EasyEnsembleClassifier(...)\n",
    "y_pred_eec = eec.predict(X_test)\n",
    "acc_eec = accuracy_score(y_test, y_pred_eec)\n",
    "\n",
    "auc_eec = roc_auc_score(y_test, y_pred_eec, average=None)\n",
    "print (\"Overall Easy Ensemble Classifier accuracy: \", acc_eec)\n",
    "print (\"Overall Easy Ensemble Classifier ROC_AUC: \", auc_eec)\n",
    "print(confusion_matrix(y_test, y_pred_eec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall AdaBoost Classifier accuracy:  0.9761044176706827\n",
      "Overall AdaBoost Classifier ROC_AUC:  0.9378233257513234\n",
      "[[4197   31]\n",
      " [  88  664]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create and fit an AdaBoosted decision tree\n",
    "bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators=50)\n",
    "\n",
    "bdt.fit(X_train, y_train) \n",
    "y_pred_bdt = bdt.predict(X_test)\n",
    "acc_bdt = accuracy_score(y_test, y_pred_bdt)\n",
    "\n",
    "auc_bdt = roc_auc_score(y_test, y_pred_bdt, average=None)\n",
    "print (\"Overall AdaBoost Classifier accuracy: \", acc_bdt)\n",
    "print (\"Overall AdaBoost Classifier ROC_AUC: \", auc_bdt)\n",
    "print(confusion_matrix(y_test, y_pred_bdt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost-sensitive AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Cost-sensitive AdaBoost Classifier accuracy:  0.9736947791164658\n",
      "Overall Cost-sensitive AdaBoost Classifier ROC_AUC:  0.9544431500231486\n",
      "[[4152   76]\n",
      " [  55  697]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create and fit an AdaBoosted decision tree sample weighted\n",
    "\n",
    "sample_weight_constant = np.ones(len(y_train))\n",
    "# and bigger weights to some outliers\n",
    "sample_weight_constant[np.where(y_train == 1)] *= 5\n",
    "bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators=50)\n",
    "\n",
    "y_pred_cs_bdt = bdt.fit(X_train, y_train, sample_weight_constant).predict(X_test) \n",
    "acc_cs_bdt = accuracy_score(y_test, y_pred_cs_bdt)\n",
    "\n",
    "auc_cs_bdt = roc_auc_score(y_test, y_pred_cs_bdt, average=None)\n",
    "print (\"Overall Cost-sensitive AdaBoost Classifier accuracy: \", acc_cs_bdt)\n",
    "print (\"Overall Cost-sensitive AdaBoost Classifier ROC_AUC: \", auc_cs_bdt)\n",
    "print(confusion_matrix(y_test, y_pred_cs_bdt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Random Forest Classifier accuracy:  0.9771084337349397\n",
      "Overall Random Forest Classifier ROC_AUC:  0.9252953964451781\n",
      "[[4226    2]\n",
      " [ 112  640]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "rfc = RandomForestClassifier(max_depth=4, random_state=0)\n",
    "rfc.fit(X_train, y_train) \n",
    "RandomForestClassifier(...)\n",
    "\n",
    "y_pred_rfc = rfc.predict(X_test)\n",
    "acc_cs_rfc = accuracy_score(y_test, y_pred_rfc)\n",
    "\n",
    "auc_rfc = roc_auc_score(y_test, y_pred_rfc, average=None)\n",
    "print (\"Overall Random Forest Classifier accuracy: \", acc_cs_rfc)\n",
    "print (\"Overall Random Forest Classifier ROC_AUC: \", auc_rfc)\n",
    "print(confusion_matrix(y_test, y_pred_rfc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Cost sensitive support vector machine (CS-SVM) is another version of support vector machine (SVM) that is modified in order to deal with the issue of class imbalance. I propose a model referred to as SMOTE-CS-SVM integrating the application of The Synthetic Minority Oversampling Technique (SMOTE) with CS-SVM . The experimental findings reveal that the proposed model outperforms not only LR, SVM and CS-SVM but also three other state-of-the-art classifiers including EasyEnsemble, cost-sensitive adaptive boosting, random forest. In this regard, I conclude that the proposed  model is a decent and practical approach to support credit card fraud detection of highly imbalanced data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
